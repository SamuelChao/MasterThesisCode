{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import os.path as osp\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import runpy\n",
    "import scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = input(\"Please enter the directory: \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_ba_path = 'SERS_debaseline.py'\n",
    "k = 0\n",
    "for dirpath, dirnames, filenames in os.walk(input_dir):\n",
    "    for filenames_index in filenames :\n",
    "        print(filenames_index)\n",
    "        folder_name = filenames_index.split('.')[0]\n",
    "        label = folder_name\n",
    "        # folder_name = folder_name + '_' + str(k)  \n",
    "        print(folder_name)\n",
    "        print(filenames_index)\n",
    "        dir = dirpath + '/' + folder_name +'/'\n",
    "        print(dir)\n",
    "        os.makedirs(dir, exist_ok = True)\n",
    "\n",
    "        file = dirpath + '/' + filenames_index\n",
    "        dest = dir + '/' + label + '.txt'\n",
    "        de_path = dir+'/' + 'debase.py'\n",
    "        shutil.move(file, dest)\n",
    "        shutil.copy(de_ba_path, de_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0\n",
    "for dirpath, dirnames, filenames in os.walk(input_dir):\n",
    "    for filenames_index in filenames :\n",
    "        if filenames_index == 'debase.py':\n",
    "            #print (dirpath, dirnames, filenames_index)\n",
    "            fi = dirpath + '/' + filenames_index\n",
    "            file_globals = runpy.run_path(fi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave = np.arange(400, 1550.1, 0.5, dtype=float)\n",
    "feature = np.zeros((1,2301))\n",
    "labels = []\n",
    "\n",
    "k = 0\n",
    "for dirpath, dirnames, filenames in os.walk(input_dir):\n",
    "    # print(dirpath, dirnames, filenames)\n",
    "    if dirpath[-2:] == 'sb':\n",
    "        # print(filenames)\n",
    "        df = pd.read_csv(dirpath + '/'+ filenames[0])\n",
    "        df = df.loc[:, '400':'1550']\n",
    "        df = df.to_numpy()\n",
    "        feature = np.row_stack((feature, df))\n",
    "        label = '_'.join(filenames[0].split(\"_\")[1:-3])\n",
    "        # print(label)\n",
    "        labels.extend([label]*df.shape[0])\n",
    "\n",
    "\n",
    "feature = feature[1:,:]\n",
    "# label = [labels] * feature.shape[0]\n",
    "print(feature.shape)\n",
    "df = pd.DataFrame(feature, columns=wave)\n",
    "df.insert(0, 'label', labels)\n",
    "print(df)\n",
    "df.to_csv(input_dir + 'RAW_SERS_dataset.csv', index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning by 733/690 ratio >= 1.2\n",
    "\n",
    "df = pd.read_csv(input_dir + 'RAW_SERS_dataset.csv', header = 0)\n",
    "\n",
    "## Cleaning \n",
    "substrate_area = df.loc[:, '680.0':'700.0']\n",
    "characteristic_area = df.loc[:, '720.0':'760.0']\n",
    "substrate_peak = substrate_area.max(axis=1).to_numpy()\n",
    "characteristic_peak = characteristic_area.max(axis=1).to_numpy()\n",
    "peak_ratio = characteristic_peak / substrate_peak\n",
    "peak_ratio = peak_ratio[np.logical_not(np.isnan(peak_ratio))] \n",
    "\n",
    "\n",
    "sort_ratio_index = np.argsort(peak_ratio)\n",
    "print(sort_ratio_index)\n",
    "ratio_threshold = 1.2  ## Retain data with ratio > 1.2\n",
    "print(peak_ratio.shape)\n",
    "print(peak_ratio[sort_ratio_index])\n",
    "a = 0\n",
    "for i in range(peak_ratio.shape[0]):\n",
    "    if peak_ratio[sort_ratio_index[i]] > ratio_threshold:\n",
    "        a = i\n",
    "        break\n",
    "\n",
    "\n",
    "qualified_ratio = sort_ratio_index[a:]\n",
    "qualified_ratio = list(qualified_ratio)\n",
    "qualified_ratio.sort()\n",
    "df = df.iloc[qualified_ratio, :]\n",
    "clean_count = df['label'].value_counts()\n",
    "clean_count.to_csv(input_dir +'Cleaned_SERS_dataset_Count.csv', index= True)\n",
    "\n",
    "df.to_csv(input_dir + 'Cleaned_SERS_dataset.csv', index= False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### For Datalabel representation \n",
    "\n",
    "data_path = input_dir + 'Cleaned_SERS_dataset.csv'\n",
    "df = pd.read_csv(data_path, header = 0)\n",
    "\n",
    "df['label'].replace({\n",
    "# 'Adenine' :'0',\n",
    "'Ecoli-BW25113_Amp0_30min': '0',   \n",
    "'Ecoli-BW25113_Amp4_30min': '1', \n",
    "'Ecoli-BW25113_Amp8_30min': '1',  \n",
    "'Ecoli-BW25113_Amp16_30min':'2', \n",
    "'Ecoli-BW25113_Amp32_30min':'2',   \n",
    "'Ecoli-DH5alpha_Amp0_30min':'3', \n",
    "'Ecoli-DH5alpha_Amp2_30min':'4',  \n",
    "'Ecoli-DH5alpha_Amp4_30min' :'4',\n",
    "'Ecoli-DH5alpha_Amp8_30min'  :'5',\n",
    "'Ecoli-DH5alpha_Amp16_30min'  :'5',\n",
    "'Ecoli-DH5alpha-ampR_Amp0_30min':'3',\n",
    "'Ecoli-DH5alpha-ampR_Amp2_30min':'6',\n",
    "'Ecoli-DH5alpha-ampR_Amp4_30min':'6',\n",
    "'Ecoli-DH5alpha-ampR_Amp8_30min' :'6',  \n",
    "'Ecoli-DH5alpha-ampR_Amp16_30min' :'6'}, inplace=True)\n",
    "\n",
    "\n",
    "df.to_csv(input_dir + 'Labeled_SERS_dataset.csv', index= False )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test dataset split\n",
    "\n",
    "data_path = input_dir + 'Labeled_SERS_dataset.csv'\n",
    "df = pd.read_csv(data_path, header = 0)\n",
    "cols = list(df.columns)\n",
    "\n",
    "# print(df['label'])\n",
    "\n",
    "combine = df.to_numpy()\n",
    "np.random.seed(4001)\n",
    "np.random.shuffle(combine)\n",
    "print (combine.shape)\n",
    "\n",
    "percent10 = int (combine.shape[0] * 0.1)\n",
    "print(percent10)\n",
    "\n",
    "test_set = combine[0:percent10,:]\n",
    "train_set = combine[percent10:,:]\n",
    "\n",
    "test_set = pd.DataFrame(test_set, columns=cols)\n",
    "train_set = pd.DataFrame(train_set, columns=cols)\n",
    "\n",
    "test_set.to_csv(input_dir  + 'SERS_testing.csv', index= False , header = True)\n",
    "train_set.to_csv(input_dir + 'SERS_training.csv', index= False , header = True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "899abd191a9ea73a89afb19849dc406f29b830785484ec2528e59ce4ca659ec1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
